{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3c02b53f-a1d3-4126-89b4-f63c2f05d453",
   "metadata": {},
   "source": [
    "### Checkpoint 2 - Part 1 - Resampling Techniques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "96e176a4-383a-4b66-91c3-4564f8984311",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# for EDA\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import seaborn as sns\n",
    "import matplotlib.colors\n",
    "import matplotlib.ticker as mtick\n",
    "\n",
    "\n",
    "# feature scaler\n",
    "from sklearn.preprocessing import StandardScaler, OrdinalEncoder\n",
    "\n",
    "# for fixing the imbalanced dataset and split\n",
    "from imblearn.over_sampling import SMOTE, ADASYN\n",
    "from imblearn.under_sampling import RandomUnderSampler, EditedNearestNeighbours\n",
    "from imblearn.combine import SMOTEENN\n",
    "\n",
    "# for model evaluation\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, mean_squared_error\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "# models selection \n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import svm\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "\n",
    "\n",
    "# for the gridsearch\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c0a75b2a-a5fb-4fa7-a80c-aecd6db686ec",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Load the data using Pandas\n",
    "filePath = '/Users/namithabhaskar/Documents/MsSem4ClassworkAssignments/capstoneProject/Data/Diabetes/archive/diabetes_binary_health_indicators_BRFSS2015.csv'\n",
    "fulldf = pd.read_csv(filePath)\n",
    "filePath1 = '/Users/namithabhaskar/Documents/MsSem4ClassworkAssignments/capstoneProject/Data/Diabetes/archive/diabetes_binary_5050split_health_indicators_BRFSS2015.csv'\n",
    "baldf = pd.read_csv(filePath1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fdd3b834-955b-4758-bba0-79e3a38a2ef7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Diabetes_binary</th>\n",
       "      <th>HighBP</th>\n",
       "      <th>HighChol</th>\n",
       "      <th>CholCheck</th>\n",
       "      <th>BMI</th>\n",
       "      <th>Smoker</th>\n",
       "      <th>Stroke</th>\n",
       "      <th>HeartDiseaseorAttack</th>\n",
       "      <th>PhysActivity</th>\n",
       "      <th>Fruits</th>\n",
       "      <th>...</th>\n",
       "      <th>AnyHealthcare</th>\n",
       "      <th>NoDocbcCost</th>\n",
       "      <th>GenHlth</th>\n",
       "      <th>MentHlth</th>\n",
       "      <th>PhysHlth</th>\n",
       "      <th>DiffWalk</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>Education</th>\n",
       "      <th>Income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Diabetes_binary  HighBP  HighChol  CholCheck   BMI  Smoker  Stroke  \\\n",
       "0              0.0     1.0       1.0        1.0  40.0     1.0     0.0   \n",
       "1              0.0     0.0       0.0        0.0  25.0     1.0     0.0   \n",
       "2              0.0     1.0       1.0        1.0  28.0     0.0     0.0   \n",
       "3              0.0     1.0       0.0        1.0  27.0     0.0     0.0   \n",
       "4              0.0     1.0       1.0        1.0  24.0     0.0     0.0   \n",
       "\n",
       "   HeartDiseaseorAttack  PhysActivity  Fruits  ...  AnyHealthcare  \\\n",
       "0                   0.0           0.0     0.0  ...            1.0   \n",
       "1                   0.0           1.0     0.0  ...            0.0   \n",
       "2                   0.0           0.0     1.0  ...            1.0   \n",
       "3                   0.0           1.0     1.0  ...            1.0   \n",
       "4                   0.0           1.0     1.0  ...            1.0   \n",
       "\n",
       "   NoDocbcCost  GenHlth  MentHlth  PhysHlth  DiffWalk  Sex   Age  Education  \\\n",
       "0          0.0      5.0      18.0      15.0       1.0  0.0   9.0        4.0   \n",
       "1          1.0      3.0       0.0       0.0       0.0  0.0   7.0        6.0   \n",
       "2          1.0      5.0      30.0      30.0       1.0  0.0   9.0        4.0   \n",
       "3          0.0      2.0       0.0       0.0       0.0  0.0  11.0        3.0   \n",
       "4          0.0      2.0       3.0       0.0       0.0  0.0  11.0        5.0   \n",
       "\n",
       "   Income  \n",
       "0     3.0  \n",
       "1     1.0  \n",
       "2     8.0  \n",
       "3     6.0  \n",
       "4     4.0  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fulldf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "15cfd65a-2668-43e2-8f17-87e82a42c37d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Diabetes_binary</th>\n",
       "      <th>HighBP</th>\n",
       "      <th>HighChol</th>\n",
       "      <th>CholCheck</th>\n",
       "      <th>BMI</th>\n",
       "      <th>Smoker</th>\n",
       "      <th>Stroke</th>\n",
       "      <th>HeartDiseaseorAttack</th>\n",
       "      <th>PhysActivity</th>\n",
       "      <th>Fruits</th>\n",
       "      <th>...</th>\n",
       "      <th>AnyHealthcare</th>\n",
       "      <th>NoDocbcCost</th>\n",
       "      <th>GenHlth</th>\n",
       "      <th>MentHlth</th>\n",
       "      <th>PhysHlth</th>\n",
       "      <th>DiffWalk</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>Education</th>\n",
       "      <th>Income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>253675</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>253676</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>253677</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>253678</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>253679</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Diabetes_binary  HighBP  HighChol  CholCheck   BMI  Smoker  Stroke  \\\n",
       "253675              0.0     1.0       1.0        1.0  45.0     0.0     0.0   \n",
       "253676              1.0     1.0       1.0        1.0  18.0     0.0     0.0   \n",
       "253677              0.0     0.0       0.0        1.0  28.0     0.0     0.0   \n",
       "253678              0.0     1.0       0.0        1.0  23.0     0.0     0.0   \n",
       "253679              1.0     1.0       1.0        1.0  25.0     0.0     0.0   \n",
       "\n",
       "        HeartDiseaseorAttack  PhysActivity  Fruits  ...  AnyHealthcare  \\\n",
       "253675                   0.0           0.0     1.0  ...            1.0   \n",
       "253676                   0.0           0.0     0.0  ...            1.0   \n",
       "253677                   0.0           1.0     1.0  ...            1.0   \n",
       "253678                   0.0           0.0     1.0  ...            1.0   \n",
       "253679                   1.0           1.0     1.0  ...            1.0   \n",
       "\n",
       "        NoDocbcCost  GenHlth  MentHlth  PhysHlth  DiffWalk  Sex   Age  \\\n",
       "253675          0.0      3.0       0.0       5.0       0.0  1.0   5.0   \n",
       "253676          0.0      4.0       0.0       0.0       1.0  0.0  11.0   \n",
       "253677          0.0      1.0       0.0       0.0       0.0  0.0   2.0   \n",
       "253678          0.0      3.0       0.0       0.0       0.0  1.0   7.0   \n",
       "253679          0.0      2.0       0.0       0.0       0.0  0.0   9.0   \n",
       "\n",
       "        Education  Income  \n",
       "253675        6.0     7.0  \n",
       "253676        2.0     4.0  \n",
       "253677        5.0     2.0  \n",
       "253678        5.0     1.0  \n",
       "253679        6.0     2.0  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fulldf.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2781841f-8e20-4c66-a7d2-1546215f65c2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 253680 entries, 0 to 253679\n",
      "Data columns (total 22 columns):\n",
      " #   Column                Non-Null Count   Dtype  \n",
      "---  ------                --------------   -----  \n",
      " 0   Diabetes_binary       253680 non-null  float64\n",
      " 1   HighBP                253680 non-null  float64\n",
      " 2   HighChol              253680 non-null  float64\n",
      " 3   CholCheck             253680 non-null  float64\n",
      " 4   BMI                   253680 non-null  float64\n",
      " 5   Smoker                253680 non-null  float64\n",
      " 6   Stroke                253680 non-null  float64\n",
      " 7   HeartDiseaseorAttack  253680 non-null  float64\n",
      " 8   PhysActivity          253680 non-null  float64\n",
      " 9   Fruits                253680 non-null  float64\n",
      " 10  Veggies               253680 non-null  float64\n",
      " 11  HvyAlcoholConsump     253680 non-null  float64\n",
      " 12  AnyHealthcare         253680 non-null  float64\n",
      " 13  NoDocbcCost           253680 non-null  float64\n",
      " 14  GenHlth               253680 non-null  float64\n",
      " 15  MentHlth              253680 non-null  float64\n",
      " 16  PhysHlth              253680 non-null  float64\n",
      " 17  DiffWalk              253680 non-null  float64\n",
      " 18  Sex                   253680 non-null  float64\n",
      " 19  Age                   253680 non-null  float64\n",
      " 20  Education             253680 non-null  float64\n",
      " 21  Income                253680 non-null  float64\n",
      "dtypes: float64(22)\n",
      "memory usage: 42.6 MB\n"
     ]
    }
   ],
   "source": [
    "fulldf.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fe2a79a9-2844-4876-ad82-fcff3a30314b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Diabetes_binary         0\n",
       "HighBP                  0\n",
       "HighChol                0\n",
       "CholCheck               0\n",
       "BMI                     0\n",
       "Smoker                  0\n",
       "Stroke                  0\n",
       "HeartDiseaseorAttack    0\n",
       "PhysActivity            0\n",
       "Fruits                  0\n",
       "Veggies                 0\n",
       "HvyAlcoholConsump       0\n",
       "AnyHealthcare           0\n",
       "NoDocbcCost             0\n",
       "GenHlth                 0\n",
       "MentHlth                0\n",
       "PhysHlth                0\n",
       "DiffWalk                0\n",
       "Sex                     0\n",
       "Age                     0\n",
       "Education               0\n",
       "Income                  0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fulldf.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0f6699e2-536a-402a-b0ae-fa164b64e700",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24206"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fulldf.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c6a5d59c-4674-4718-a5b2-64edb6ab69bd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fulldf.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b2d5414c-8952-40c1-b5b4-8c5a708c71a6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fulldf.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "545df7fa-bcb3-4ae6-8fc3-ee98f34d83a2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fulldf = fulldf.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2192ecb1-cc05-491a-a82a-dc7a7b026b2b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 229474 entries, 0 to 253679\n",
      "Data columns (total 22 columns):\n",
      " #   Column                Non-Null Count   Dtype\n",
      "---  ------                --------------   -----\n",
      " 0   Diabetes_binary       229474 non-null  int64\n",
      " 1   HighBP                229474 non-null  int64\n",
      " 2   HighChol              229474 non-null  int64\n",
      " 3   CholCheck             229474 non-null  int64\n",
      " 4   BMI                   229474 non-null  int64\n",
      " 5   Smoker                229474 non-null  int64\n",
      " 6   Stroke                229474 non-null  int64\n",
      " 7   HeartDiseaseorAttack  229474 non-null  int64\n",
      " 8   PhysActivity          229474 non-null  int64\n",
      " 9   Fruits                229474 non-null  int64\n",
      " 10  Veggies               229474 non-null  int64\n",
      " 11  HvyAlcoholConsump     229474 non-null  int64\n",
      " 12  AnyHealthcare         229474 non-null  int64\n",
      " 13  NoDocbcCost           229474 non-null  int64\n",
      " 14  GenHlth               229474 non-null  int64\n",
      " 15  MentHlth              229474 non-null  int64\n",
      " 16  PhysHlth              229474 non-null  int64\n",
      " 17  DiffWalk              229474 non-null  int64\n",
      " 18  Sex                   229474 non-null  int64\n",
      " 19  Age                   229474 non-null  int64\n",
      " 20  Education             229474 non-null  int64\n",
      " 21  Income                229474 non-null  int64\n",
      "dtypes: int64(22)\n",
      "memory usage: 40.3 MB\n"
     ]
    }
   ],
   "source": [
    "fulldf.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5b9caf9d-28d5-4bd8-9cc6-a63783fad6a3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X = fulldf.drop(columns=['Diabetes_binary']) \n",
    "y = fulldf['Diabetes_binary']  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9365793f-5381-4645-a32e-97cb015d2130",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/namithabhaskar/anaconda3/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [08:55:44] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 28078, number of negative: 155501\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.009427 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 218\n",
      "[LightGBM] [Info] Number of data points in the train set: 183579, number of used features: 21\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.152948 -> initscore=-1.711666\n",
      "[LightGBM] [Info] Start training from score -1.711666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/namithabhaskar/anaconda3/lib/python3.11/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/namithabhaskar/anaconda3/lib/python3.11/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/namithabhaskar/anaconda3/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [10:28:49] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 155501, number of negative: 155501\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010478 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3988\n",
      "[LightGBM] [Info] Number of data points in the train set: 311002, number of used features: 21\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/namithabhaskar/anaconda3/lib/python3.11/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/namithabhaskar/anaconda3/lib/python3.11/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/namithabhaskar/anaconda3/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [11:58:04] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 152541, number of negative: 155501\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.010478 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4006\n",
      "[LightGBM] [Info] Number of data points in the train set: 308042, number of used features: 21\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.495195 -> initscore=-0.019219\n",
      "[LightGBM] [Info] Start training from score -0.019219\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/namithabhaskar/anaconda3/lib/python3.11/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/namithabhaskar/anaconda3/lib/python3.11/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/namithabhaskar/anaconda3/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [12:00:02] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 28078, number of negative: 28078\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001883 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 214\n",
      "[LightGBM] [Info] Number of data points in the train set: 56156, number of used features: 21\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/namithabhaskar/anaconda3/lib/python3.11/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/namithabhaskar/anaconda3/lib/python3.11/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/namithabhaskar/anaconda3/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [12:13:40] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 28078, number of negative: 109588\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006542 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 217\n",
      "[LightGBM] [Info] Number of data points in the train set: 137666, number of used features: 21\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.203957 -> initscore=-1.361742\n",
      "[LightGBM] [Info] Start training from score -1.361742\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/namithabhaskar/anaconda3/lib/python3.11/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/namithabhaskar/anaconda3/lib/python3.11/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/namithabhaskar/anaconda3/lib/python3.11/site-packages/xgboost/core.py:158: UserWarning: [12:42:30] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 135407, number of negative: 97758\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.006967 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 4027\n",
      "[LightGBM] [Info] Number of data points in the train set: 233165, number of used features: 21\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.580735 -> initscore=0.325790\n",
      "[LightGBM] [Info] Start training from score 0.325790\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/namithabhaskar/anaconda3/lib/python3.11/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "/Users/namithabhaskar/anaconda3/lib/python3.11/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Resampling                Model  Train Accuracy  Train F1  \\\n",
      "0    Baseline  Logistic Regression        0.850397  0.232806   \n",
      "1    Baseline          Naive Bayes        0.755500  0.416267   \n",
      "2    Baseline                  KNN        0.994591  0.981999   \n",
      "3    Baseline        Decision Tree        0.851176  0.214801   \n",
      "4    Baseline                  SVM        0.777714  0.272174   \n",
      "..        ...                  ...             ...       ...   \n",
      "61  SMOTE-ENN    Gradient Boosting        0.917153  0.929319   \n",
      "62  SMOTE-ENN             AdaBoost        0.877091  0.895637   \n",
      "63  SMOTE-ENN              XGBoost        0.948436  0.955083   \n",
      "64  SMOTE-ENN             LightGBM        0.943113  0.950505   \n",
      "65  SMOTE-ENN             CatBoost        0.954877  0.960637   \n",
      "\n",
      "    Train Recall (Class 0)  Train Recall (Class 1)  Test Accuracy   Test F1  \\\n",
      "0                 0.977151                0.148408       0.850528  0.239299   \n",
      "1                 0.788998                0.569984       0.756727  0.423146   \n",
      "2                 1.000000                0.964634       0.823009  0.271937   \n",
      "3                 0.980836                0.133094       0.852773  0.225559   \n",
      "4                 0.869075                0.271743       0.778952  0.277370   \n",
      "..                     ...                     ...            ...       ...   \n",
      "61                0.888490                0.937847       0.733609  0.460507   \n",
      "62                0.834070                0.908151       0.684236  0.437116   \n",
      "63                0.954571                0.944006       0.791415  0.471368   \n",
      "64                0.946613                0.940587       0.790282  0.472747   \n",
      "65                0.964248                0.948112       0.796165  0.472393   \n",
      "\n",
      "    Test Recall (Class 0)  Test Recall (Class 1)  Test Precision  \n",
      "0                0.976335               0.153726        0.539770  \n",
      "1                0.788018               0.583416        0.331955  \n",
      "2                0.932581               0.216128        0.366602  \n",
      "3                0.981428               0.140191        0.576788  \n",
      "4                0.869508               0.277390        0.277350  \n",
      "..                    ...                    ...             ...  \n",
      "61               0.731840               0.743411        0.333568  \n",
      "62               0.663031               0.801681        0.300475  \n",
      "63               0.824519               0.608064        0.384851  \n",
      "64               0.821972               0.614760        0.384033  \n",
      "65               0.832184               0.596666        0.390963  \n",
      "\n",
      "[66 rows x 11 columns]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "# Standardize features (Important for models like Logistic Regression, SVM, and KNN)\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Define models\n",
    "models = {\n",
    "    \"Logistic Regression\": LogisticRegression(max_iter=500, random_state=508312),\n",
    "    \"Naive Bayes\": GaussianNB(),\n",
    "    \"KNN\": KNeighborsClassifier(n_neighbors=5, weights='distance', metric='manhattan'),\n",
    "    \"Decision Tree\": DecisionTreeClassifier(criterion='entropy', max_depth=5),\n",
    "    \"SVM\": svm.SVC(kernel='sigmoid', C=1.0),\n",
    "    \"Random Forest\": RandomForestClassifier(random_state=508312),\n",
    "    \"Gradient Boosting\": GradientBoostingClassifier(random_state=508312),\n",
    "    \"AdaBoost\": AdaBoostClassifier(estimator=DecisionTreeClassifier(max_depth=1), n_estimators=50),\n",
    "    \"XGBoost\": XGBClassifier(random_state=508312, use_label_encoder=False, eval_metric='logloss'),\n",
    "    \"LightGBM\": LGBMClassifier(n_estimators=100, learning_rate=0.1, num_leaves=31),\n",
    "    \"CatBoost\": CatBoostClassifier(random_state=508312, verbose=False)  # Suppress output\n",
    "}\n",
    "\n",
    "# Define resampling techniques\n",
    "resampling_methods = {\n",
    "    \"Baseline\": None,  # No resampling\n",
    "    \"SMOTE\": SMOTE(random_state=42),\n",
    "    \"ADASYN\": ADASYN(random_state=42),\n",
    "    \"Random Undersampling (RUS)\": RandomUnderSampler(random_state=42),\n",
    "    \"Edited Nearest Neighbors (ENN)\": EditedNearestNeighbours(),\n",
    "    \"SMOTE-ENN\": SMOTEENN(random_state=42)\n",
    "}\n",
    "\n",
    "# Store results\n",
    "results = []\n",
    "\n",
    "# Iterate over each resampling method\n",
    "for resample_name, resampler in resampling_methods.items():\n",
    "    # Apply resampling\n",
    "    if resampler is None:\n",
    "        X_resampled, y_resampled = X_train, y_train\n",
    "    else:\n",
    "        X_resampled, y_resampled = resampler.fit_resample(X_train, y_train)\n",
    "    \n",
    "    # Train and evaluate each model\n",
    "    for model_name, model in models.items():\n",
    "        model.fit(X_resampled, y_resampled)  # Train model\n",
    "        \n",
    "        # Predictions on Train and Test Data\n",
    "        y_train_pred = model.predict(X_resampled)\n",
    "        y_test_pred = model.predict(X_test)\n",
    "        \n",
    "        # Compute evaluation metrics for training data\n",
    "        train_accuracy = accuracy_score(y_resampled, y_train_pred)\n",
    "        train_recall_0 = recall_score(y_resampled, y_train_pred, pos_label=0)\n",
    "        train_recall_1 = recall_score(y_resampled, y_train_pred, pos_label=1)\n",
    "        train_f1 = f1_score(y_resampled, y_train_pred, average='binary')\n",
    "\n",
    "        # Compute evaluation metrics for test data\n",
    "        test_accuracy = accuracy_score(y_test, y_test_pred)\n",
    "        test_precision = precision_score(y_test, y_test_pred, average='binary', zero_division=0)\n",
    "        test_recall_0 = recall_score(y_test, y_test_pred, pos_label=0)\n",
    "        test_recall_1 = recall_score(y_test, y_test_pred, pos_label=1)\n",
    "        test_f1 = f1_score(y_test, y_test_pred, average='binary')\n",
    "\n",
    "        # Store results\n",
    "        results.append([\n",
    "            resample_name, model_name,\n",
    "            train_accuracy, train_f1, train_recall_0, train_recall_1,\n",
    "            test_accuracy, test_f1, test_recall_0, test_recall_1, test_precision\n",
    "        ])\n",
    "\n",
    "# Convert results to DataFrame\n",
    "results_df = pd.DataFrame(results, columns=[\n",
    "    \"Resampling\", \"Model\",\n",
    "    \"Train Accuracy\", \"Train F1\", \"Train Recall (Class 0)\", \"Train Recall (Class 1)\",\n",
    "    \"Test Accuracy\", \"Test F1\", \"Test Recall (Class 0)\", \"Test Recall (Class 1)\", \"Test Precision\"\n",
    "])\n",
    "\n",
    "# Display results\n",
    "print(results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "fa2a92a2-bfc0-42ac-bdb0-f4b3ad38b1a9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ”¹ Baseline Results:\n",
      "\n",
      "Resampling               Model  Train Accuracy  Test Accuracy  Test F1  Test Recall (Class 0)  Test Recall (Class 1)\n",
      "  Baseline Logistic Regression        0.850397       0.850528 0.239299               0.976335               0.153726\n",
      "  Baseline         Naive Bayes        0.755500       0.756727 0.423146               0.788018               0.583416\n",
      "  Baseline                 KNN        0.994591       0.823009 0.271937               0.932581               0.216128\n",
      "  Baseline       Decision Tree        0.851176       0.852773 0.225559               0.981428               0.140191\n",
      "  Baseline                 SVM        0.777714       0.778952 0.277370               0.869508               0.277390\n",
      "  Baseline       Random Forest        0.994553       0.843861 0.247743               0.965866               0.168115\n",
      "  Baseline   Gradient Boosting        0.853774       0.855213 0.263059               0.979113               0.168970\n",
      "  Baseline            AdaBoost        0.850043       0.852577 0.304911               0.968335               0.211426\n",
      "  Baseline             XGBoost        0.863508       0.853361 0.269431               0.975512               0.176806\n",
      "  Baseline            LightGBM        0.856460       0.856128 0.263798               0.980271               0.168543\n",
      "  Baseline            CatBoost        0.867458       0.853971 0.268979               0.976438               0.175666\n",
      "\n",
      "-------------------------------------------------------------------------------------\n",
      "\n",
      "ðŸ”¹ SMOTE Results:\n",
      "\n",
      "Resampling               Model  Train Accuracy  Test Accuracy  Test F1  Test Recall (Class 0)  Test Recall (Class 1)\n",
      "     SMOTE Logistic Regression        0.740243       0.715350 0.448497               0.707866               0.756803\n",
      "     SMOTE         Naive Bayes        0.713545       0.695087 0.428256               0.685770               0.746688\n",
      "     SMOTE                 KNN        0.996807       0.733871 0.367609               0.775054               0.505770\n",
      "     SMOTE       Decision Tree        0.756725       0.756292 0.435072               0.782051               0.613620\n",
      "     SMOTE                 SVM        0.644018       0.645038 0.358799               0.644254               0.649380\n",
      "     SMOTE       Random Forest        0.996804       0.834775 0.338018               0.935693               0.275823\n",
      "     SMOTE   Gradient Boosting        0.879737       0.828304 0.446162               0.896208               0.452201\n",
      "     SMOTE            AdaBoost        0.791988       0.749690 0.455235               0.761575               0.683858\n",
      "     SMOTE             XGBoost        0.914148       0.853971 0.292441               0.972528               0.197322\n",
      "     SMOTE            LightGBM        0.911316       0.855039 0.313345               0.970367               0.216270\n",
      "     SMOTE            CatBoost        0.921766       0.853971 0.282595               0.974200               0.188061\n",
      "\n",
      "-------------------------------------------------------------------------------------\n",
      "\n",
      "ðŸ”¹ ADASYN Results:\n",
      "\n",
      "Resampling               Model  Train Accuracy  Test Accuracy  Test F1  Test Recall (Class 0)  Test Recall (Class 1)\n",
      "    ADASYN Logistic Regression        0.721564       0.705480 0.445320               0.693281               0.773045\n",
      "    ADASYN         Naive Bayes        0.695340       0.682013 0.425252               0.666272               0.769198\n",
      "    ADASYN                 KNN        0.996776       0.725678 0.364911               0.763659               0.515316\n",
      "    ADASYN       Decision Tree        0.744872       0.685456 0.417668               0.676047               0.737569\n",
      "    ADASYN                 SVM        0.624707       0.630112 0.343339               0.629720               0.632284\n",
      "    ADASYN       Random Forest        0.996773       0.834187 0.326429               0.937365               0.262715\n",
      "    ADASYN   Gradient Boosting        0.877773       0.830766 0.443983               0.900993               0.441801\n",
      "    ADASYN            AdaBoost        0.779744       0.745245 0.450667               0.756431               0.683288\n",
      "    ADASYN             XGBoost        0.912178       0.854646 0.290546               0.973814               0.194615\n",
      "    ADASYN            LightGBM        0.910405       0.854821 0.303543               0.971808               0.206867\n",
      "    ADASYN            CatBoost        0.921004       0.853688 0.281588               0.973969               0.187491\n",
      "\n",
      "-------------------------------------------------------------------------------------\n",
      "\n",
      "ðŸ”¹ Random Undersampling (RUS) Results:\n",
      "\n",
      "                Resampling               Model  Train Accuracy  Test Accuracy  Test F1  Test Recall (Class 0)  Test Recall (Class 1)\n",
      "Random Undersampling (RUS) Logistic Regression        0.730519       0.714522 0.447872               0.706837               0.757088\n",
      "Random Undersampling (RUS)         Naive Bayes        0.704751       0.693823 0.425793               0.685076               0.742271\n",
      "Random Undersampling (RUS)                 KNN        0.997062       0.663907 0.395074               0.654208               0.717624\n",
      "Random Undersampling (RUS)       Decision Tree        0.716023       0.688485 0.428417               0.674967               0.763357\n",
      "Random Undersampling (RUS)                 SVM        0.641356       0.646541 0.357494               0.647186               0.642969\n",
      "Random Undersampling (RUS)       Random Forest        0.997044       0.694738 0.433207               0.682452               0.762787\n",
      "Random Undersampling (RUS)   Gradient Boosting        0.740063       0.707092 0.452446               0.691892               0.791281\n",
      "Random Undersampling (RUS)            AdaBoost        0.731658       0.712387 0.449174               0.702567               0.766776\n",
      "Random Undersampling (RUS)             XGBoost        0.775073       0.701972 0.446907               0.686568               0.787292\n",
      "Random Undersampling (RUS)            LightGBM        0.750641       0.704085 0.450718               0.687879               0.793845\n",
      "Random Undersampling (RUS)            CatBoost        0.767950       0.706025 0.451857               0.690452               0.792278\n",
      "\n",
      "-------------------------------------------------------------------------------------\n",
      "\n",
      "ðŸ”¹ Edited Nearest Neighbors (ENN) Results:\n",
      "\n",
      "                    Resampling               Model  Train Accuracy  Test Accuracy  Test F1  Test Recall (Class 0)  Test Recall (Class 1)\n",
      "Edited Nearest Neighbors (ENN) Logistic Regression        0.857641       0.809282 0.457985               0.860274               0.526856\n",
      "Edited Nearest Neighbors (ENN)         Naive Bayes        0.804033       0.724371 0.420734               0.736984               0.654509\n",
      "Edited Nearest Neighbors (ENN)                 KNN        0.997472       0.767055 0.414929               0.808031               0.540105\n",
      "Edited Nearest Neighbors (ENN)       Decision Tree        0.849643       0.821985 0.428031               0.891758               0.435532\n",
      "Edited Nearest Neighbors (ENN)                 SVM        0.784246       0.738098 0.358386               0.785009               0.478273\n",
      "Edited Nearest Neighbors (ENN)       Random Forest        0.997443       0.797255 0.454220               0.841599               0.551646\n",
      "Edited Nearest Neighbors (ENN)   Gradient Boosting        0.865915       0.813160 0.471364               0.861637               0.544664\n",
      "Edited Nearest Neighbors (ENN)            AdaBoost        0.860024       0.810524 0.461815               0.860891               0.531557\n",
      "Edited Nearest Neighbors (ENN)             XGBoost        0.881220       0.806450 0.469703               0.850859               0.560479\n",
      "Edited Nearest Neighbors (ENN)            LightGBM        0.870505       0.808716 0.472574               0.853560               0.560336\n",
      "Edited Nearest Neighbors (ENN)            CatBoost        0.884474       0.810088 0.472078               0.856107               0.555207\n",
      "\n",
      "-------------------------------------------------------------------------------------\n",
      "\n",
      "ðŸ”¹ SMOTE-ENN Results:\n",
      "\n",
      "Resampling               Model  Train Accuracy  Test Accuracy  Test F1  Test Recall (Class 0)  Test Recall (Class 1)\n",
      " SMOTE-ENN Logistic Regression        0.849561       0.649831 0.425687               0.613952               0.848554\n",
      " SMOTE-ENN         Naive Bayes        0.800043       0.686633 0.422270               0.675404               0.748825\n",
      " SMOTE-ENN                 KNN        1.000000       0.672470 0.403587               0.663057               0.724605\n",
      " SMOTE-ENN       Decision Tree        0.857968       0.677198 0.426242               0.657912               0.784015\n",
      " SMOTE-ENN                 SVM        0.781717       0.616603 0.382076               0.587998               0.775039\n",
      " SMOTE-ENN       Random Forest        0.999996       0.769561 0.460628               0.792340               0.643396\n",
      " SMOTE-ENN   Gradient Boosting        0.917153       0.733609 0.460507               0.731840               0.743411\n",
      " SMOTE-ENN            AdaBoost        0.877091       0.684236 0.437116               0.663031               0.801681\n",
      " SMOTE-ENN             XGBoost        0.948436       0.791415 0.471368               0.824519               0.608064\n",
      " SMOTE-ENN            LightGBM        0.943113       0.790282 0.472747               0.821972               0.614760\n",
      " SMOTE-ENN            CatBoost        0.954877       0.796165 0.472393               0.832184               0.596666\n",
      "\n",
      "-------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "columns_to_display = [\"Resampling\", \"Model\", \"Train Accuracy\", \"Test Accuracy\", \"Test F1\", \n",
    "                      \"Test Recall (Class 0)\", \"Test Recall (Class 1)\"]\n",
    "\n",
    "for technique, df_subset in results_df.groupby(\"Resampling\", sort=False):\n",
    "    print(f\"\\nðŸ”¹ {technique} Results:\\n\")\n",
    "    print(df_subset[columns_to_display].to_string(index=False))  # Display selected columns\n",
    "    print(\"\\n\" + \"-\" * 85)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10e849c0-19bf-4472-8592-aa91de7f6369",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
